{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r doc_behavior \n",
    "%store -r doc_ephys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = './data/hc-3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_behavior = doc_behavior[[os.path.isdir(os.path.join(data_directory,t,s)) for t,s in doc_behavior[['topdir','session']].values]]\n",
    "doc_ephys = doc_ephys[doc_ephys['topdir'].isin(doc_behavior['topdir'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom as dom\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 2\n",
    "    \n",
    "session = doc_behavior.iloc[s].copy()\n",
    "\n",
    "session['directory'] = os.path.join(data_directory,session['topdir'],session['session'])\n",
    "\n",
    "session_files = sorted(os.listdir(session['directory']))\n",
    "session_files = [f for f in session_files if f.startswith(session['session'])]\n",
    "\n",
    "session_files_size = [os.path.getsize(os.path.join(session['directory'],f)) for f in session_files]\n",
    "\n",
    "session_files_extension = [f[len(session['session'])+1:] for f in session_files]\n",
    "session_files_extension = [re.findall('[a-z0-9]+',f)[0] for f in session_files_extension]\n",
    "\n",
    "session_files_shank     = [re.findall('.([0-9]+)$',f) for f in session_files]\n",
    "session_files_shank     = [int(s[0]) if len(s) else np.nan for s in session_files_shank]\n",
    "\n",
    "session['files'] = pd.DataFrame({\n",
    "    'name' : session_files,\n",
    "    'path' : [os.path.join(session['directory'],f) for f in session_files],\n",
    "    'size' : session_files_size,\n",
    "    'shank' : session_files_shank,\n",
    "    'extension' : session_files_extension,\n",
    "}).sort_values(by='shank')\n",
    "\n",
    "xml_filepath = os.path.join(session['directory'],session['session']+'.xml')\n",
    "\n",
    "session_xml = dom.parse(xml_filepath)\n",
    "params = session_xml.getElementsByTagName('parameters')[0].childNodes[1:-1:2]\n",
    "\n",
    "params = { param.nodeName:param for p,param in enumerate(params) }\n",
    "xml_info = {}\n",
    "xml_info.update({gi.nodeName:gi.childNodes[0].nodeValue for gi in params['generalInfo'].childNodes[1::2] if gi.childNodes})\n",
    "xml_info.update({gi.nodeName:int(gi.childNodes[0].nodeValue) for gi in params['acquisitionSystem'].childNodes[1::2] if gi.childNodes})\n",
    "xml_info.update({gi.nodeName:int(gi.childNodes[0].nodeValue) for gi in params['fieldPotentials'].childNodes[1::2] if gi.childNodes})\n",
    "\n",
    "xml_info['channels'] = {}\n",
    "for s,shank in enumerate(params['anatomicalDescription'].childNodes[1].childNodes[1:-1:2]):\n",
    "    for c,channel in enumerate(shank.childNodes[1:-1:2]):\n",
    "        contact = int(channel.childNodes[0].nodeValue)\n",
    "        skip = bool(int(channel.getAttribute('skip')))\n",
    "        xml_info['channels'].update({contact : {\n",
    "            'shank':s+1,\n",
    "            'contact' : c,\n",
    "            'skip' : skip,\n",
    "            'area' : session['elepos'].get(s+1)\n",
    "        }})\n",
    "\n",
    "xml_info['spike'] = {}\n",
    "for g,group in enumerate(params['spikeDetection'].childNodes[1].childNodes[1::2]):\n",
    "    entries = group.childNodes[1::2]\n",
    "    xml_info['spike'][g+1] = {entry.nodeName : int(entry.childNodes[0].nodeValue) if e != 0 else [int(node.childNodes[0].nodeValue) for node in entry.childNodes[1::2]] for e,entry in enumerate(entries)}\n",
    "    xml_info['spike'][g+1]['shank'] = g+1\n",
    "    xml_info['spike'][g+1]['nChannels'] = len(xml_info['spike'][g+1]['channels'])\n",
    "\n",
    "\n",
    "for k,v in xml_info.items():\n",
    "    session[k] = v\n",
    "\n",
    "session['nshanks'] = int(session['nshanks'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "session['spikes'] = {}\n",
    "\n",
    "session['spike']['srate'] = session['samplingRate']\n",
    "for shank in range(1,session['nshanks']+1):\n",
    "    shank_files = session['files'].query('shank == %d' % shank)    \n",
    "    \n",
    "    spk_file = shank_files.query('extension == \"spk\"').iloc[0]\n",
    "    \n",
    "    nsamples  = session['spike'][shank]['nSamples']\n",
    "    nchannels = session['spike'][shank]['nChannels']\n",
    "    nspikes   = spk_file['size'] // 2 // nsamples // nchannels\n",
    "\n",
    "    session['spike'][shank]['file'] = spk_file\n",
    "    session['spike'][shank]['nSpikes'] = nspikes\n",
    "    session['spike'][shank]['waveform'] = np.memmap(spk_file['path'],dtype='int16',mode='r',shape=(nspikes,nsamples,nchannels))\n",
    "    \n",
    "    fet_file = shank_files.query('extension == \"fet\"').iloc[0]\n",
    "\n",
    "    with open(fet_file['path'],'r') as f:\n",
    "        fet_content1 = f.readlines()\n",
    "        fet_content = np.array([[f for f in f.strip().split(' ')] for f in fet_content1[1:]])\n",
    "    \n",
    "    session['spike'][shank]['features'] = fet_content[:,:-2].astype(int)\n",
    "\n",
    "    clu_file = shank_files.query('extension == \"clu\"').iloc[0]\n",
    "\n",
    "    with open(clu_file['path'],'r') as f:\n",
    "        clu_content = np.array(f.readlines(),dtype=int)\n",
    "        nClusters = clu_content[0]\n",
    "        clu_content = clu_content[1:]\n",
    "    \n",
    "    session['spike'][shank]['nClusters'] = nClusters\n",
    "    session['spike'][shank]['cluster'] = clu_content\n",
    "    session['spike'][shank]['clusters'] = np.unique(clu_content)\n",
    "    \n",
    "    id_topdir    = doc_ephys['topdir'] == session['topdir']\n",
    "    id_cluster   = doc_ephys['clu'].isin(session['spike'][shank]['clusters'])\n",
    "    id_electrode = doc_ephys['ele'] == shank\n",
    "\n",
    "    session['spike'][shank]['meta'] = doc_ephys[id_topdir & id_cluster & id_electrode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_file = session['files'].query('extension == \"eeg\"').iloc[0]\n",
    "\n",
    "session['eeg'] = {}\n",
    "session['eeg']['file']     = eeg_file\n",
    "session['eeg']['nSamples'] = session['eeg']['file']['size'] // 2 // session['nChannels']\n",
    "session['eeg']['data']     = np.memmap(session['eeg']['file']['path'],dtype='int16',mode='r',shape=(session['eeg']['nSamples'],session['nChannels']))\n",
    "session['eeg']['srate'] = session['lfpSamplingRate']\n",
    "session['eeg']['time'] = np.arange(0,session['eeg']['nSamples'])/session['eeg']['srate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "whl_file = session['files'].query('extension == \"whl\"').iloc[0]\n",
    "\n",
    "session['tracking'] = {}\n",
    "session['tracking']['file'] = whl_file\n",
    "session['tracking']['srate'] = 39.0625 \n",
    "session['tracking']['data'] = pd.read_csv(whl_file['path'],sep='\\t',header=None).replace(-1,np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'session' (Series)\n"
     ]
    }
   ],
   "source": [
    "%store session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
